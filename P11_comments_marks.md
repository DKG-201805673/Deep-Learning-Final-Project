**Project 11 - OCR for information extraction for semi-structured scanned documents**

In this report, “OCR for information extraction for semi-structured scanned documents”, it is presented a data pipeline focusing on document digitalisation based on the OCR technology.

The Introduction section is split into three subsections comprising motivation, a brief description of OCR and the methodology for designing a 3-stage pipeline account for text localisation, text recognition (including tokenisation), and key information extraction. One of the alleged contributions is the specific calibration of each pipeline stage, in opposition to traditional all-in-one approaches. The section lacks a summary of results and some general comments on the main findings, as expected from an introductory section.

The solution concept comprises a 3-stage pipeline for text localisation, text recognition and classification/topic modelling. The first stage employs a combined CNN-RNN model based on the Tesseract architecture. The report/code presents a detailed implementation of such stage, including data preparation, exploratory data analysis, and results. It is commented on the complexity involved in such a task and the decision of deploying the first two stages (text localisation and recognition) as a unique block, based on reference models. The second stage focuses on identifying bounding boxes and performing tokenisation, based on a set of pre-trained tokenisers and the `Seq2SeqTrainer` model. Finally, the last stage is dedicated to key-information extraction, based on the `LayoutLM` model from a reference paper. Overall, the solution is appropriate to the proposed problem and aggregates a set of different models to reflect the proposed pipeline. Regarding the report, a figure summarising all models and their main characteristics would help in better understanding the proposed solution.

The implementation is split into three parts to reflect the proposed pipeline. There is extensive code covering each part, with references to external repositories and other sources. Looking at each part separately, it seems you have tried to achieve the best possible implementation, which is fine. Looking at the pipeline as a whole, it is not always clear how the information flows from one stage to another - although you have provided some comments in each section. Again, a figure summarising your design and showing data/control flow would help here. It is also important to clearly state which part of the code was used "as is" (from a referenced source) and which part was designed from scratch. This would help in better assessing the complexity and programming effort around your solution. As the code is too long, it would be nice to draft a separate report (PDF file for instance) summarising the main points - this would save time for reading and allow you to highlight your contributions. Finally, as you mix TensorFlow and PyTorch, it would be nice to provide some detailed instructions for reproducibility purposes.

The dataset is *SROIE* (scanned receipts OCR and key information extraction), consisting of JPG images for receipts, a text file with the bounding boxes’ coordinates for each piece of text, and a JSON file with entities labels for the company name, address, date, and total amount. There are 626 images, txt files, and json files, including duplicates. All necessary data preprocessing steps are performed and clearly noted in the code. Overall, the dataset is fine and appropriate to the problem. It would be nice to test with other datasets, or comment on the expected generalisability of your models to other types of documents.

The numerical evaluation is specific to each pipeline stage. For text localisation, there is some output showing whether the Tesseract model was able to clearly identify the text, but some error/fail is also reported. As both stages were merged, it would be nice to clearly indicate which metrics are useful to test the output of each stage. It is reported a good F1 score (together with training and validation loss) for most cases. The last part is assessed against labelling, training, and prediction tasks. The model is able to correct label a good set of samples, but generates a significant number of "other" (label O) labels. This could be a result of the small, specific dataset used for training and worth further tests. Regarding the layout model, the results are quite impressive. Overall, the pipeline seems to be stable and provides good results. It would be nice to test it against other types of data. For the report, a summary of all metrics used in each stage with corresponding results would help.

The conclusion section summarises the proposed work, highlighting contributions and limitations from each stage. Some ideas for further work are also discussed for each part, including dealing with noisy images, extending to other languages, performing automatic labelling, and testing the models for a longer time.

The presentation quality is overall good but a separate report with the main parts would be a better approach, given the size and complexity of your code.

Overall, this is an interesting work combining different models to implement a complex pipeline.

**Marks**

**Total weighted sum: 75**
